# the loadbalancer is specific for production/staging HA environments
# via Rancher and not available on docker hub
# comment it if you just want to deploy locally for development/testing 
loadbalancer:
  ports:
  - 8111:80 # this is the only port that actually needs to be exposed on host for all traffic to the search apps
  restart: always
  labels:
    io.rancher.loadbalancer.target.pam: pam.demo.eea.europa.eu=3000
    io.rancher.loadbalancer.target.pam: pam.apps.eea.europa.eu=3000
    io.rancher.loadbalancer.target.aide: aide.demo.eea.europa.eu=3000
    io.rancher.loadbalancer.target.aide: aide.apps.eea.europa.eu=3000
    io.rancher.scheduler.affinity:host_label: balancer=true
    io.rancher.loadbalancer.target.eeasearch: search.demo.eea.europa.eu=3000
    io.rancher.loadbalancer.target.eeasearch: search.apps.eea.europa.eu=3000
  image: rancher/load-balancer-service
  links:
  - pam:pam
  - aide:aide
  - eeasearch:eeasearch

eeasearch:
    image: eeacms/eeasearch:v1.1
    restart: always
    links:
        - esclient
    ports:
        - 3000:3000
    volumes:
        - /code
    environment:
        - elastic_host=esclient
        - SYNC_CRONTAB=30 * * * * # Sync every 30 minutes
    labels:
        io.rancher.scheduler.affinity:host_label: elastic=yes

pam:
    image: eeacms/pam:v2.1
    restart: always
    links:
        - esclient
    ports:
        - 3010:3000 # Take up host 3010 port, can be removed if you use the loadbalancer
    volumes:
        - /code
    environment:
        - elastic_host=esclient
    labels:
        io.rancher.scheduler.affinity:host_label: elastic=yes

aide:
    image: eeacms/aide:v1.0-rc4
    restart: always
    links:
        - esclient
    ports:
        - 3020:3000 # Take up host 3020 port
    volumes:
        - /code
    environment:
        - elastic_host=esclient
        - SYNC_CRONTAB=0 4 * * * # Sync every 30 minutes
    labels:
        io.rancher.scheduler.affinity:host_label: elastic=yes

## ES Simple cluster with dedicated nodes
esmaster:
    image: eeacms/elastic:1.7.1-1.5.7
    restart: always
    command: # No data, no http, no river, can be master
        - elasticsearch
        - -Des.cluster.name="SearchServices"
        - -Des.node.data=false
        - -Des.http.enabled=false
        - -Des.node.master=true
        - -Des.node.river=_none_
    volumes_from:
        - datam
    labels:
        io.rancher.sidekicks: datam
        io.rancher.scheduler.affinity:host_label: elastic=yes

## Use an explicit data container for master node
datam:
    image: busybox
    tty: true
    command:
        - cat
    volumes:
        - /usr/share/elasticsearch/data
    stdin_open: true

esclient:
    image: eeacms/elastic:1.7.1-1.5.7
    restart: always
    command: # No data, http, no river, can't be master
        - elasticsearch
        - -Des.cluster.name="SearchServices"
        - -Des.node.data=false
        - -Des.http.enabled=true
        - -Des.node.master=false
        - -Des.node.river=_none_
    ports:
        - 9200:9200
    labels:
        io.rancher.scheduler.affinity:host_label: elastic=yes

## Explicit adding of workers as there have to be at least two initial shards
# Do not perform docker scale over these containers as
# shards will get lost
esworker1:
    image: eeacms/elastic:1.7.1-1.5.7
    restart: always
    command: # Data, no http, river, can't be master
        - elasticsearch
        - -Des.cluster.name="SearchServices"
        - -Des.node.data=true
        - -Des.http.enabled=false
        - -Des.node.master=false
    volumes_from:
        - dataw1
    environment:
        - ES_HEAP_SIZE=2g
    labels:
        io.rancher.sidekicks: dataw1
        io.rancher.scheduler.affinity:host_label: elastic=yes

## Data is persistent by default for the containers but explicit data
# containers are needed for automated backup operations
dataw1:
    image: busybox
    tty: true
    command:
        - cat
    volumes:
        - /usr/share/elasticsearch/data
    stdin_open: true

esworker2:
    image: eeacms/elastic:1.7.1-1.5.7
    restart: always
    command: # Data, no http, river, can't be master
        - elasticsearch
        - -Des.cluster.name="SearchServices"
        - -Des.node.data=true
        - -Des.http.enabled=false
        - -Des.node.master=false
    volumes_from:
        - dataw2
    environment:
        - ES_HEAP_SIZE=2g
    labels:
        io.rancher.sidekicks: dataw2
        io.rancher.scheduler.affinity:host_label: elastic=yes

dataw2:
    image: busybox
    tty: true
    command:
        - cat
    volumes:
        - /usr/share/elasticsearch/data
    stdin_open: true
